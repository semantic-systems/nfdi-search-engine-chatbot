{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "df = pd.read_csv(\"search_results.csv\", converters={'clean': literal_eval, 'bert_sim': literal_eval, 'tfidf_sim': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for sim_scores in df.bert_sim:\n",
    "  if len(sim_scores) >= 100:\n",
    "    X = np.array(sim_scores)\n",
    "    kmeans = KMeans(n_clusters=30, random_state=0, n_init=\"auto\").fit(X.reshape(-1,1))\n",
    "  else:\n",
    "    X = np.array(sim_scores)\n",
    "    kmeans = KMeans(n_clusters=10, random_state=0, n_init=\"auto\").fit(X.reshape(-1,1))\n",
    "  clusters.append(kmeans.labels_)\n",
    "\n",
    "df['k_mean_clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "gpt_responses = []\n",
    "for sentences, labels in tqdm(zip(df.clean, df.k_mean_clusters)):\n",
    "  k_clusters = defaultdict(list)\n",
    "  for res, label in zip(sentences, labels):\n",
    "    # Assign title to corresponding cluster\n",
    "    k_clusters[label].append(res)\n",
    "\n",
    "  response_clusters = []\n",
    "  for key, val in k_clusters.items():\n",
    "    if len(val) < 5:\n",
    "      # Do not process if cluster contains less than 5 titles\n",
    "      response_clusters.append(None)\n",
    "      continue\n",
    "\n",
    "    prompt = f\"\"\"The task is to generate questions based on provided information.\n",
    "    Given list of texts generate only two questions, no more than two questions. \n",
    "    Make questions variant.\n",
    "    The questions should be what a user is looking for and not questions that seek to do fact-checking.\n",
    "\n",
    "    Format output as a python list.\n",
    "\n",
    "    Information:\n",
    "    ```{val}```\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-4\",\n",
    "      messages=[\n",
    "        {\"role\": \"assistant\", \"content\":prompt}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    response_clusters.append(response.choices[0].message.content)\n",
    "  gpt_responses.append(response_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt_questions'] = gpt_responses"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
