{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q rank-bm25\n",
    "pip install -q sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(path):\n",
    "  with open(path, 'r') as j:\n",
    "      contents = json.loads(j.read())\n",
    "\n",
    "  search_key, elapsed_time, publications, resources, others, results, result_lines, results_num = [], [], [], [], [], [], [], []\n",
    "  for result in contents:\n",
    "      # pprint(result)\n",
    "      search_key.append(result['search_key'])\n",
    "      elapsed_time.append(result['elapsed_time'])\n",
    "      # results.append(result['results'])\n",
    "      publications.append(result['stats']['publications'])\n",
    "      if 'resources' in result['stats']:\n",
    "          resources.append(result['stats'][\"resources\"])\n",
    "      else:\n",
    "          resources.append(None)\n",
    "      if 'others' in result['stats']:\n",
    "          others.append(result['stats'][\"others\"])\n",
    "      else:\n",
    "          others.append(None)\n",
    "      result_lines= []\n",
    "      num = 0\n",
    "      for line in result['results']:\n",
    "          result_lines.append(line)\n",
    "          num += 1\n",
    "      results.append(result_lines)\n",
    "      results_num.append(num)\n",
    "\n",
    "  df = pd.DataFrame([search_key, elapsed_time, publications, resources, others, results_num, results]).T\n",
    "  df = df.rename(columns={0: 'search_key', 1: 'elapsed_time', 2: 'publications', 3: 'resources', 4: 'others', 5: 'results_num', 6: 'results'})\n",
    "  return df, contents\n",
    "\n",
    "df, contents = json_to_df(\"/export/home/0usmanov/data/search_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def cleanDoc(doc):\n",
    "    stopset = set(stopwords.words('english'))\n",
    "    #stemmer = nltk.PorterStemmer()\n",
    "    tokens = WordPunctTokenizer().tokenize(doc)\n",
    "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token)>2]\n",
    "    #final = [stemmer.stem(word) for word in clean]\n",
    "    return clean\n",
    "\n",
    "def remove_urls(text, replacement_text=\"\"):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text_without_urls = url_pattern.sub(replacement_text, text)\n",
    "    return text_without_urls\n",
    "\n",
    "def clean_text(contents)\n",
    "  clean = []\n",
    "  for c in contents:\n",
    "    r_tokens = []\n",
    "    for r in c['results']:\n",
    "      url_removed = remove_urls(r)\n",
    "      r_tokens.append(' '.join(cleanDoc(url_removed.rstrip())))#.apply(lambda x: ' '.join(map(str, x))))\n",
    "    clean.append(r_tokens)\n",
    "  return clean\n",
    "\n",
    "#df['tokens'] = tokens\n",
    "df['clean'] = clean_text(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "#df = pd.read_csv(\"search_res3.csv\", converters={'clean': literal_eval, 'clean_stem': literal_eval, 'bert_sim': literal_eval, 'tfidf_sim': literal_eval, 'bm25_sim': literal_eval})\n",
    "\n",
    "print(df.shape)\n",
    "df = df[df['results_num'] < 300]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_bar(df, col1, col2):\n",
    "  fig = px.bar(df, x=\"num\", y=\"type\", \n",
    "              orientation='h',\n",
    "              height=400,\n",
    "              title='Number of results per source')\n",
    "  fig.show()\n",
    "\n",
    "def get_hist(df, column, title):\n",
    "  import plotly.express as px\n",
    "\n",
    "  fig = px.histogram(df,\n",
    "       x=column,\n",
    "       marginal='box',\n",
    "       title=title\n",
    "       )\n",
    "\n",
    "  fig.add_vline(x=2.2, line_width=1, line_dash='dash', line_color='gray', col=1)\n",
    "\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df[['publications','resources', 'others']].sum().reset_index().rename(columns={'index': 'type', 0: 'num'})\n",
    "plot_bar(plot_df, \"num\", \"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hist(df, 'results_num', 'Results number distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hist(df, 'elapsed_time', 'Response time distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1, specs=[[{\"type\": \"bar\"}], [{\"type\": \"xy\"}], [{\"type\": \"xy\"}]],\n",
    "            subplot_titles=('Number of results per source', 'Results number distribution', 'Response time distribution'))\n",
    "\n",
    "#res_num_plot = filtered_df[['publications','resources', 'others']].sum().reset_index().rename(columns={'index': 'type', 0: 'num'})\n",
    "plot1 = px.bar(plot_df, x=\"num\", y=\"type\", orientation='h')\n",
    "plot2 = px.histogram(df, x='results_num', marginal='box')\n",
    "plot2.add_vline(x=2.2, line_width=1, line_dash='dash', line_color='gray', col=1)\n",
    "plot3 = px.histogram(df, x='elapsed_time', marginal='box')\n",
    "plot3.add_vline(x=2.2, line_width=1, line_dash='dash', line_color='gray', col=1)\n",
    "\n",
    "fig.append_trace(plot1.data[0],row=1, col=1)\n",
    "#fig.append_trace(plot2.data[1], row=2, col=1)\n",
    "fig.append_trace(plot2.data[0], row=2, col=1)\n",
    "#fig.append_trace(plot3.data[1], row=3, col=1)\n",
    "fig.append_trace(plot3.data[0], row=2, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=800, width=600)#, title_text=\"Stacked Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import recall_score\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_recall(similarities, threshold):\n",
    "    recalls = []\n",
    "    for sim in similarities:\n",
    "      filtered_sum = 0\n",
    "      for val in sim:\n",
    "        if val >= threshold:\n",
    "          filtered_sum += 1\n",
    "\n",
    "      recall = filtered_sum/len(sim)\n",
    "      recalls.append(recall)\n",
    "    return sum(recalls)/len(recalls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_cosine_scores(search_keys, documents):\n",
    "  similarities = []\n",
    "  # Calculate tfidf vectors\n",
    "  for key,res_texts in zip(search_keys, documents):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    query_tfidf = tfidf_vectorizer.fit_transform([key]).toarray()\n",
    "    document_tfidf = tfidf_vectorizer.transform(res_texts).toarray()\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarities = cosine_similarity(query_tfidf, document_tfidf)\n",
    "    similarities.append(cosine_similarities[0])\n",
    "  return similarities\n",
    "\n",
    "df['tfidf_sim'] = get_tfidf_cosine_scores(df['search_key'], df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_bert_simlirarities(search_keys, documents):\n",
    "    similarities = []\n",
    "    for key,res_texts in zip(search_keys, documents):\n",
    "      # Compute embedding for both lists\n",
    "      embeddings1 = model.encode(res_texts, convert_to_tensor=True)\n",
    "      embeddings2 = model.encode([key], convert_to_tensor=True)\n",
    "\n",
    "      # Compute cosine-similarities\n",
    "      cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "      similarities.append(cosine_scores.reshape(-1).tolist())\n",
    "\n",
    "    return similarities\n",
    "\n",
    "df['bert_sim'] = get_bert_simlirarities(df['search_key'], df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def get_bm25_similarities(search_keys, documents):\n",
    "  similarities = []\n",
    "  for key,res_texts in zip(search_keys, documents):\n",
    "    corpus = \" \".join(res_texts)\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "\n",
    "    # Calculate BM25 scores for each search key\n",
    "    bm25_scores = []\n",
    "    scores = bm25.get_scores(key)\n",
    "    bm25_scores.append(scores)\n",
    "\n",
    "    # Convert BM25 scores to cosine similarities\n",
    "    max_score = np.max(bm25_scores)\n",
    "    cosine_similarities = [np.array(scores) / max_score for scores in bm25_scores]\n",
    "    similarities.append(cosine_similarities[0])\n",
    "  return similarities\n",
    "\n",
    "df['bm25_sim'] = get_bm25_similarities(df['search_key'], df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "tfidf_plot_vals = []\n",
    "bert_plot_vals = []\n",
    "bm25_plot_vals = []\n",
    "for t in thresholds:\n",
    "  tfidf_plot_vals.append(get_threshold_recall(df['tfidf_sim'], t))\n",
    "  bert_plot_vals.append(get_threshold_recall(df['bert'], t))\n",
    "  bm25_plot_vals.append(get_threshold_recall(df['bm25_sim'], t))\n",
    "\n",
    "f1 = go.Figure(\n",
    "    data = [\n",
    "        go.Scatter(x=thresholds, y=tfidf_plot_vals, name=\"TFIDF\"),\n",
    "        go.Scatter(x=thresholds, y=bert_plot_vals, name=\"BERT\"),\n",
    "        go.Scatter(x=thresholds, y=bm25_plot_vals, name=\"BM25\"),\n",
    "    ],\n",
    "    layout = {\"xaxis\": {\"title\": \"Thresholds\"}, \"yaxis\": {\"title\": \"Average recall for similarity scores\"}, \"title\": \"Recall analysis\"}\n",
    ")\n",
    "\n",
    "f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
